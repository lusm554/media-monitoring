import re
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

WHITESPACE_HANDLER = lambda k: re.sub('\s+', ' ', re.sub('\n+', ' ', k.strip()))

article_text = """
ВТБ прогнозирует объем рынка ЦФА по итогам года около 400 млрд рублей

По итогам 2024 года объем рынка цифровых финансовых активов (ЦФА) в России приблизится к 400 млрд рублей. Об этом в рамках ВЭФ-2024 в эфире телеканала РБК ТВ заявил член правления ВТБ Виталий Сергейчук.

«Объем рынка ЦФА в 2024 году уже превысил 200 млрд руб. и может достигнуть 400 млрд руб. Этот рынок активно развивается, его доходность уже сейчас зачастую превышает доходность по сопоставимым биржевым инструментам. Поэтому мы видим большой потенциал роста спроса на данный продукт со стороны инвесторов», – рассказал Виталий Сергейчук.

Он также отметил, что для более активного развития рынка ЦФА необходима автоматизация сделок. «Сейчас ограничен инструментарий, доступный физическим лицам. Как только мы переведем форму или возможность инвестирования в ЦФА в привычный для людей интерфейс – приложения брокерские и банковские в телефоне – будет гораздо больше спрос и всплеск интереса со стороны розничного инвестора к данному продукту», – отметил спикер.

Напомним, что в этом году ВТБ первым в России предложил частным инвесторам цифровые финансовые активы, привязанные к стоимости физического квадратного метра в строящемся жилом комплексе hideOUT. Этот инструмент радикально снизил для розничных инвесторов порог входа на рынок инвестиций в премиальную недвижимость. Доходность и защита капитала инвесторов аналогичны приобретению физического метра жилья в этом ЖК.
"""

model_name = "csebuetnlp/mT5_multilingual_XLSum"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

input_ids = tokenizer(
    [WHITESPACE_HANDLER(article_text)],
    return_tensors="pt",
    padding="max_length",
    truncation=True,
    max_length=512
)["input_ids"]

output_ids = model.generate(
    input_ids=input_ids,
    max_length=84,
    no_repeat_ngram_size=2,
    num_beams=4
)[0]

summary = tokenizer.decode(
    output_ids,
    skip_special_tokens=True,
    clean_up_tokenization_spaces=False
)

print(summary)

